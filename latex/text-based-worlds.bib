@inproceedings{cote_textworld_2019,
 abstract = {We introduce TextWorld, a sandbox learning environment for the training and evaluation of RL agents on text-based games. TextWorld is a Python library that handles interactive play-through of text games, as well as backend functions like state tracking and reward assignment. It comes with a curated list of games whose features and challenges we have analyzed. More significantly, it enables users to handcraft or automatically generate new games. Its generative mechanisms give precise control over the difficulty, scope, and language of constructed games, and can be used to relax challenges inherent to commercial text games like partial observability and sparse rewards. By generating sets of varied but similar games, TextWorld can also be used to study generalization and transfer learning. We cast text-based games in the Reinforcement Learning formalism, use our framework to develop a set of benchmark games, and evaluate several baseline agents on this set and the curated list.},
 address = {Cham},
 author = {Côté, Marc-Alexandre and Kádár, Ákos and Yuan, Xingdi and Kybartas, Ben and Barnes, Tavian and Fine, Emery and Moore, James and Hausknecht, Matthew and El Asri, Layla and Adada, Mahmoud and Tay, Wendy and Trischler, Adam},
 doi = {10.1007/978-3-030-24337-1_3},
 editor = {Cazenave, Tristan and Saffidine, Abdallah and Sturtevant, Nathan},
 isbn = {9783030243371},
 language = {en},
 pages = {41--75},
 publisher = {Springer International Publishing},
 series = {Communications in {Computer} and {Information} {Science}},
 shorttitle = {{TextWorld}},
 title = {{TextWorld}: {A} {Learning} {Environment} for {Text}-{Based} {Games}},
 url = {https://arxiv.org/pdf/1806.11532},
 year = {2019}
}

@article{dambekodi_playing_2020,
 abstract = {Text based games are simulations in which an agent interacts with the world purely through natural language. They typically consist of a number of puzzles interspersed with interactions with common everyday objects and locations. Deep reinforcement learning agents can learn to solve these puzzles. However, the everyday interactions with the environment, while trivial for human players, present as additional puzzles to agents. We explore two techniques for incorporating commonsense knowledge into agents. Inferring possibly hidden aspects of the world state with either a commonsense inference model COMET, or a language model BERT. Biasing an agents exploration according to common patterns recognized by a language model. We test our technique in the 9to05 game, which is an extreme version of a text based game that requires numerous interactions with common, everyday objects in common, everyday scenarios. We conclude that agents that augment their beliefs about the world state with commonsense inferences are more robust to observational errors and omissions of common elements from text descriptions.},
 author = {Dambekodi, Sahith and Frazier, Spencer and Ammanabrolu, Prithviraj and Riedl, Mark O.},
 journal = {arXiv:2012.02757 [cs]},
 keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
 month = {December},
 note = {arXiv: 2012.02757},
 title = {Playing {Text}-{Based} {Games} with {Common} {Sense}},
 url = {http://arxiv.org/abs/2012.02757},
 urldate = {2022-04-14},
 year = {2020}
}


